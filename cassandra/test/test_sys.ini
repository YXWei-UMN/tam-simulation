[cluster]
num_nodes = 3
node_config = node_config

[node_config]
cpu_freq = 1
num_cpus = 1
disk_bandwidth = 100
network_bandwidth = 1000
resource_monitor_interval = 1

[drf_scheduler]
type = DRF
number_of_resources = 3

[cassandra]
stage_monitor_interval = 1
pnode_type = original ; determine the scheduling architecture
node_token_sum = 256
replication_strategy = random
token_allocation_strategy = random
common_stg_num_workers = 1 ; for the stages do not care ?
common_stg_scheduler = drf_scheduler ; use this scheduler for all the stages
common_stg_schedule_resource = all
c_req_handle_stg_num_workers = 128
c_respond_stg_num_workers = 128
msg_in_stg_num_workers = 3 ; assume n
msg_out_stg_num_workers = 9 ; should be 3 * n
request_response_stg_num_workers = 1 ; default is number of processors
read_stg_num_workers = 32 ; defulat is 32
read_stg_type_name = basic ; type of stage, could do like 'SpeculativeExec' for speculative execution
read_stg_type_enforce_res = io
read_stg_type_spec_client_id = 2
mutation_stg_num_workers = 32 ; default is 32
read_repair_stg_num_workers = 1 ; default is number of processors
replicate_on_write_stg_num_workers = 32 ; default is 32
gossip_stg_num_workers = 1 ; default is 1
anti_entropy_stg_num_workers = 1 ; default is 1
migration_stg_num_workers = 1 ; default is 1
flush_writer_stg_num_workers = 1 ; default: 1 per data directory
misc_stg_num_workers = 1 ; snapshotting, replicating data after node remove completed
internal_response_stg_num_workers = 1 ; default is number of processors, respond to no-client msg, like schema checking
hinted_handoff_stg_num_workers = 1 ; defulat is 1
memory_meter_stg_num_workers = 1 ; defulat is 1, measures memory usage and live ratio of a memtable
pend_range_calculator_stg_num_workers = 1 ; default is 1
commit_log_archiver_stg_num_workers = 1 ; default is 1
anti_entropy_session_stg_num_workers = 4 ; default is 4



