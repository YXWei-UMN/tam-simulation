[fifo_scheduler]
type = FIFO

[wfq_scheduler]
type = WFQ
weight_map = {1:1, 2:2}

[drf_scheduler]
# different schedulers need differnt configurations; for simple schedulers such as FIFO, a single type would suffice;
# for DRF, number of resources has to be specified.
# One may also specify a weight_map for DRF and WFQ scheduler, that gives differnt weight to different clients.
# check the get_scheduler() function in scheduler.py for details.
type = DRF
number_of_resources = 3
weight_map = {1:1, 2:2}

[cluster]
num_nodes = 8
node_config = node_config

[node_config]
# cpu frequncy in GHz
cpu_freq = 1
# number of cpu cores
num_cpus = 1
# disk bandwidth in MBs
disk_bandwidth = 100
# number of disks (total i/o bandidth = disk_bandwidth * num_disks
num_disks = 1
# network bandwidth in MBs
network_bandwidth = 1000
# number of network links (total network bandwidth = network_bandwidth * num_links
num_links = 2
# time internval to report resource statistics, in seconds
resource_monitor_interval = 0.1

[hdfs]
# number of data replicas stored
replica = 3
# number of rpc handler threads in namenode
namenode_handlers = 30
# scheduler for the rpc handle stage in namenode
namenode_scheduler = fifo_scheduler
# data node configuration
datanode = datanode

[datanode]
# datanode types, for now only simple is supported
datanode_type = simple
# scheduler for the xceive stage in datanode; None means on-demand, i.e. launching a new thread to process each incoming request
datanode_xceive_stage_scheduler = None
# time interval to report data node stage statistics, in seconds
stage_monitor_interval = 0.1

[hbase]
# region server types, can be original, speculative, short_circuit, async_handler, async_flusher, active_handler, sched_handler_time, sched_handler_sep_wal and others.
# each type dictats different region server behaviors; original mimics the real hbase implementation behavior.
# for details on differnt types of region server, check HBase::get_cluster in hbase.py
region_server_type = original
# region server configuration section
region_server_config = region_server

[region_server]
# number of threads in the rpc read stage
num_rpc_readers = 10
# number of threads in the rpc handle stage
num_rpc_handlers = 30
# when data in memstore (aggregated over all clients) exceeds total_mem * flush_threshold, memstore will flush data to hdfs
flush_threshold = 0.7
# number of threads in mem_flush stage
num_mem_flushers = 2
# scheduler in the rpc_read stage
rpc_read_scheduler = fifo_scheduler
# scheduler in the rpc_handle stage
rpc_handle_scheduler = drf_scheduler
# scheduler in the rpc_respond stage
rpc_respond_scheduler = fifo_scheduler
# scheduler in data stream stage; None means on-demand
data_stream_scheduler = None
# the resources to consider in the rpc_handle scheduler, "all" means consider consider cpu, i/o and network (in DRF),
# can also be "cpu", "io", "net" or others; check util/schedule_util.py for details
rpc_handle_stage_schedule_resource = all
# time internal to report region server stage statistics, in seconds
stage_monitor_interval = 0.1

